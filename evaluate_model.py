"""
Model Performance Evaluation Script
Tests Qwen3-VL on 4 document types
"""

import requests
import time
from pathlib import Path
from difflib import SequenceMatcher
from typing import List, Dict

# Configuration
API_URL = "http://localhost:8000/extract-text"

class DocumentEvaluator:
    """Evaluates model performance on different document types"""
    
    def __init__(self):
        self.results = []
    
    def calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate text similarity percentage"""
        text1 = " ".join(text1.lower().split())
        text2 = " ".join(text2.lower().split())
        similarity = SequenceMatcher(None, text1, text2).ratio()
        return similarity * 100
    
    def extract_text_from_image(self, image_path: str) -> Dict:
        """Send image to API and get extracted text"""
        try:
            start_time = time.time()
            
            with open(image_path, 'rb') as f:
                files = {'file': (Path(image_path).name, f, 'image/jpeg')}
                data = {'prompt': 'Extract all text from this image'}
                response = requests.post(API_URL, files=files, data=data, timeout=300)
            
            duration = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                return {
                    'extracted_text': result['extracted_text'],
                    'time_taken': duration,
                    'status': 'success'
                }
            else:
                return {
                    'extracted_text': '',
                    'time_taken': duration,
                    'status': 'failed'
                }
                
        except Exception as e:
            return {
                'extracted_text': '',
                'time_taken': 0,
                'status': f'error: {str(e)[:30]}'
            }
    
    def evaluate_single_image(self, test_case: Dict) -> Dict:
        """Evaluate a single test case"""
        print(f"\nüìÑ Testing: {test_case['document_type']} - {test_case['image_path']}")
        
        result = self.extract_text_from_image(test_case['image_path'])
        
        if result['status'] == 'success' and test_case.get('expected_text'):
            accuracy = self.calculate_similarity(
                result['extracted_text'], 
                test_case['expected_text']
            )
        else:
            accuracy = 0.0
        
        evaluation = {
            'document_type': test_case['document_type'],
            'image_file': Path(test_case['image_path']).name,
            'expected_text': test_case.get('expected_text', 'N/A'),
            'extracted_text': result['extracted_text'],
            'accuracy': round(accuracy, 2),
            'time_taken': round(result['time_taken'], 2),
            'status': '‚úÖ Pass' if accuracy >= 70 else '‚ùå Fail'
        }
        
        print(f"   Expected: {evaluation['expected_text'][:60]}")
        print(f"   Extracted: {evaluation['extracted_text'][:60]}")
        print(f"   Accuracy: {evaluation['accuracy']}%")
        print(f"   Time: {evaluation['time_taken']}s")
        print(f"   Status: {evaluation['status']}")
        
        self.results.append(evaluation)
        return evaluation
    
    def run_evaluation(self, test_cases: List[Dict]):
        """Run evaluation on all test cases"""
        print("="*70)
        print("üöÄ STARTING MODEL EVALUATION")
        print("="*70)
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\n[{i}/{len(test_cases)}] Processing...")
            self.evaluate_single_image(test_case)
            time.sleep(1)
        
        print("\n" + "="*70)
        print("‚úÖ EVALUATION COMPLETE")
        print("="*70)
    
    def print_summary(self):
        """Print summary statistics"""
        total_tests = len(self.results)
        avg_accuracy = sum(r['accuracy'] for r in self.results) / total_tests
        avg_time = sum(r['time_taken'] for r in self.results) / total_tests
        
        print("\n" + "="*70)
        print("üìä SUMMARY STATISTICS")
        print("="*70)
        print(f"Total Tests: {total_tests}")
        print(f"Average Accuracy: {round(avg_accuracy, 2)}%")
        print(f"Average Time: {round(avg_time, 2)} seconds")
        
        print("\n" + "="*70)
        print("üìã DETAILED RESULTS")
        print("="*70)
        print(f"{'Document Type':<25} | {'Accuracy':<10} | {'Time':<10} | {'Status':<8}")
        print("-"*70)
        for r in self.results:
            print(f"{r['document_type']:<25} | {r['accuracy']:>6.2f}%   | {r['time_taken']:>6.2f}s  | {r['status']}")
        print("="*70)


# ============================================================================
# MAIN EXECUTION
# ============================================================================

if __name__ == "__main__":
    
    # Define test cases - UPDATE WITH YOUR IMAGE PATHS AND EXPECTED TEXT
    test_cases = [
        {
            'image_path': 'test_images/english_printed.png',
            'document_type': 'English Printed',
            'expected_text': 'Today was a wonderful day. I went for a long walk in the park in the morning. The weather was warm and sunny, and the park was serene. In the afternoon, I played football with some friends. We had a lot of fun and even won the game! I\'m feeling grateful for such a great day.'
        },
        {
            'image_path': 'test_images/english_handwritten.png',
            'document_type': 'English Handwritten',
            'expected_text': 'Once there was a dog.He was very hungry.He found a piece of meat.He reaches on a bank of river.He saw his shadow in the water.He thought there was another dog in water. He became greedy. He barked to shadow to get meat.His piece of meat fell down in water.He lost his piece of meat.'
        },
        {
            'image_path': 'test_images/nepali_printed.png',
            'document_type': 'Nepali Printed',
            'expected_text': '‡§Ö‡§∞‡•ç‡§• ‡§π‡•Å‡§®‡•ç ‡§ñ‡•Å‡§∂‡•Ä ‡§ï‡§ø ‡§∏‡§Æ‡•ç‡§¨‡§®‡•ç‡§ß ‡§π‡•Å‡§®‡•ç ‡§ñ‡•Å‡§∂‡•Ä ‡§∏‡•ç‡§µ‡§§‡§®‡•ç‡§§‡•ç‡§∞ ‡§π‡•Å‡§®‡•ç ‡§ñ‡•Å‡§∂‡•Ä ‡§Ø‡§æ ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞‡§∏‡§Å‡§ó ‡§π‡•Å‡§®‡•ç ‡§ñ‡•Å‡§∂‡•Ä ‡§¨‡§æ‡§π‡•Å‡§ô‡•ç‡§ó‡§æ ‡§ñ‡•Å‡§∂‡•Ä ‡§ï‡§ø ‡§Ü‡§ú‡•à ‡§ó‡§Ø‡•Å‡§Å‡§ó‡§æ ‡§ñ‡•Å‡§∂‡•Ä'
        },
        {
            'image_path': 'test_images/nepali_handwritten.png',
            'document_type': 'Nepali Handwritten',
            'expected_text': '‡§π‡•ã‡§∏‡•ç‡§™‡§ø‡§Ø‡§æ‡§∞‡•Ä‡§ï‡§æ ‡§ö‡•á‡§§‡§æ‡§µ‡§®‡•Ä ‡§∏‡§¨‡•à‡§≤‡§æ‡§à ‡§¶‡§ø‡§¶‡•à ‡§®‡§æ‡§®‡•Ä‡§•‡§ô‡•ç‡§ï‡•Å‡§≤‡§æ‡§à ‡§ò‡§∞‡§Æ‡•à ‡§õ‡•ã‡§°‡•á‡§∞ ‡§¶‡§ø‡§®‡§≠‡§∞‡§ø ‡§ñ‡•ç‡§Ø‡•á‡§§‡§Æ‡§æ ‡§ï‡§æ‡§Æ ‡§ó‡§∞‡•ç‡§® ‡§ú‡§æ‡§®‡•á ‡§Ö‡§®‡•Å‡§ï‡•Å‡§≤ ‡§Æ‡§ø‡§≤‡§æ‡§∞‡•Å‡§ï‡§æ ‡§∂‡§ø‡§µ ‡§®‡§æ‡§∞‡§æ‡§® ‡§∞‡§ï‡•ç‡§¶‡•à ‡§§‡•ç‡§Ø‡§§‡§ø‡§¨‡•á‡§≤‡§æ ‡§ñ‡•ç‡§Ø‡•á‡§§‡§æ‡§§‡§ø‡§∞ ‡§¶‡•å‡§°‡•á ‡•§ ‡§∞‡§æ‡§§‚Äì‡§≠‡§∞‡§ø‡§ï‡•Ä ‡§á‡§§‡•ç‡§≤‡§ø‡§á‡§â‡§° ‡§Ö‡§®‡§ø‡§¶‡•ç‡§∞‡§æ‡§™‡•ç‡§∞‡§æ ‡§∂‡§ø‡§µ ‡§®‡§æ‡§∞‡§æ‡§® ‡§∞‡§ï‡•ç‡§¶‡•à ‡§§‡•ç‡§Ø‡§§‡•à ‡§¨‡•á‡§¶‡•à ‡§®‡§æ‡§®‡•Ä‡§•‡§ô‡•ç‡§ï‡•Å‡§ï‡§æ ‡§¨‡§æ‡§∞‡•Ä‡§Æ‡§æ ‡§®‡§ø‡§µ‡§∞‡•ç‡§ï‡•Ä ‡§ö‡§ø‡§§‡•ç‡§≤‡§æ ‡§ó‡§∞‡•á, ‡§®‡§æ‡§®‡§æ ‡§∏‡•ã‡§ö ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§ó‡§∞‡•á ‡•§ ‡§Ö‡§¨ ‡§®‡§æ‡§®‡•Ä‡§•‡§ô‡•ç‡§ï‡•Å‡§≤‡§æ‡§à ‡§ù‡§ü‡•ç‡§ü ‡§∞‡•Å‡§∑‡•ç‡§ü‡§æ ‡§∏‡•Å‡§™‡§æ‡§§‡•ç‡§∞‡§æ‡§∏‡•ç‡§∏‡§ø‡§§‡•ç ‡§ù‡§ø‡§ô‡•à ‡§ó‡§∞‡•á‡§∞ ‡§®‡§¶‡§ø‡§á ‡§Ø‡§∏‡•à ‡§∞‡§æ‡§§‡•Ä ‡§õ‡•ã‡§°‡§®‡•Å ‡§â‡§®‡§≤‡•á ‡§†‡•Ä‡§ï ‡§†‡§æ‡§®‡•á‡§®‡§®‡•ç ‡•§ ‡§ö‡§∞‡•à‡§Ç‡§ñ‡•á ‡§Ü‡§´‡•ç‡§®‡•à ‡§®‡§æ‡§®‡•Ä‡§•‡§ô‡•ç‡§ï‡•Å‡§≤‡§æ‡§à ‡§∞‡•Å‡§∑‡•ç‡§ü‡§æ ‡§∏‡•Å‡§ß‡•ã‡§ó‡•ç‡§Ø ‡§ò‡§∞ ‡§ö‡•ã‡§ú‡•ã ‡§ó‡§∞‡•á‡§∞ ‡§™‡§®‡§ø ‡§¶‡•Å‡§à ‡§ö‡§æ‡§∞ ‡§¶‡§ø‡§®‡•à‡§Æ‡•à ‡§µ‡§ø‡§µ‡§æ‡§π ‡§ó‡§∞‡•å‡§Ç ‡§®‡§ø‡§∂‡•ç‡§ö‡§®‡•ç‡§§ ‡§π‡•Å‡§®‡•ç ‡§™‡§∞‡•ç‡§Ø‡•ã ‡•§'
        },
    ]
    
    # Create evaluator
    evaluator = DocumentEvaluator()
    
    # Run evaluation
    evaluator.run_evaluation(test_cases)
    
    # Print summary
    evaluator.print_summary()
    
    print("\n‚ú® Evaluation complete!")
